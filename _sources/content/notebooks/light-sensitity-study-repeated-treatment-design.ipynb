{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Sensitivity Experiment: \n",
    "\n",
    "## Reporting a repeated treatment design with `ISA create mode`\n",
    "\n",
    "This example creates `ISA study descriptor` for study with sequential treatments organized in an arm. This shows how to use objects from the `isatools.create` component in a granular fashion. It creates each `Element` of the Study `Arm` at a time.\n",
    "Finally, the `study design plan` is shown by serializing the `ISA Study Design Model` content as an  `ISA_design` JSON document, which can be rendered in various ways (tables, figures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If executing the notebooks on `Google Colab`,uncomment the following command \n",
    "# and run it to install the required python libraries. Also, make the test datasets available.\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from isatools.model import (\n",
    "    Investigation,\n",
    "    Study,\n",
    "    Sample,\n",
    "    OntologyAnnotation,\n",
    "    StudyFactor,\n",
    "    FactorValue,\n",
    "    Characteristic,\n",
    "    Source,\n",
    "    Protocol,\n",
    "    Process\n",
    ")\n",
    "from isatools.create.model import (\n",
    "    Treatment,\n",
    "    NonTreatment,\n",
    "    StudyDesign,\n",
    "    StudyCell,\n",
    "    StudyArm,\n",
    "    ProductNode,\n",
    "    SampleAndAssayPlan,\n",
    "    AssayGraph\n",
    ")\n",
    "from isatools.create.constants import (\n",
    "    BASE_FACTORS,\n",
    "    SCREEN,\n",
    "    RUN_IN,\n",
    "    WASHOUT,\n",
    "    FOLLOW_UP,\n",
    "    SAMPLE,\n",
    "    EXTRACT,\n",
    "    LABELED_EXTRACT,\n",
    "    DATA_FILE\n",
    ")\n",
    "from isatools.isatab import dumps\n",
    "from isatools.isajson import ISAJSONEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "investigation = Investigation()\n",
    "investigation1 = Investigation() # to be used with the study create function\n",
    "study = Study(filename=\"s_study_xover.txt\")\n",
    "study.identifier = \"elifesprint2019-1\"\n",
    "study.title = \"elifesprint2019-1: light sensitivity\"\n",
    "study.description = \"a study about light sensitivity difference between a control population (n=10) and a genotype A population (n=10).\"\n",
    "study.submission_date = str(datetime.datetime.today())\n",
    "study.public_release_date = str(datetime.datetime.today())\n",
    "study.sources = [Source(name=\"source1\")]\n",
    "study.samples = [Sample(name=\"sample1\")]\n",
    "study.protocols = [Protocol(name=\"sample collection\")]\n",
    "study.process_sequence = [Process(executes_protocol=study.protocols[-1], inputs=[study.sources[-1]], outputs=[study.samples[-1]])]\n",
    "investigation.studies = [study]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isatools.model.Investigation(identifier='', filename='', title='', submission_date='', public_release_date='', ontology_source_references=[], publications=[], contacts=[], studies=[isatools.model.Study(filename='s_study_xover.txt', identifier='elifesprint2019-1', title='elifesprint2019-1: light sensitivity', description='a study about light sensitivity difference between a control population (n=10) and a genotype A population (n=10).', submission_date='2021-07-21 17:43:54.131318', public_release_date='2021-07-21 17:43:54.131358', contacts=[], design_descriptors=[], publications=[], factors=[], protocols=[isatools.model.Protocol(name='sample collection', protocol_type=isatools.model.OntologyAnnotation(term='', term_source=None, term_accession='', comments=[]), uri='', version='', parameters=[], components=[], comments=[])], assays=[], sources=[isatools.model.Source(name='source1', characteristics=[], comments=[])], samples=[isatools.model.Sample(name='sample1', characteristics=[], factor_values=[], derives_from=[], comments=[])], process_sequence=[isatools.model.Process(id=\"\". name=\"None\", executes_protocol=Protocol(\n",
       "    name=sample collection\n",
       "    protocol_type=\n",
       "    uri=\n",
       "    version=\n",
       "    parameters=0 ProtocolParameter objects\n",
       "    components=0 OntologyAnnotation objects\n",
       "    comments=0 Comment objects\n",
       "), date=\"None\", performer=\"None\", inputs=[isatools.model.Source(name='source1', characteristics=[], comments=[])], outputs=[isatools.model.Sample(name='sample1', characteristics=[], factor_values=[], derives_from=[], comments=[])])], other_material=[], characteristic_categories=[], comments=[], units=[])], comments=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the object :\n",
    "investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(dumps(investigation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creation of the first `ISA Study Design Element` and setting *both* `element_type` AND `duration_unit` attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonTreatment(\n",
      "            type='screen',\n",
      "            duration=isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='DURATION', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=0.0, unit=isatools.model.OntologyAnnotation(term='days', term_source=None, term_accession='', comments=[]))\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: note how duration_unit value is supplied as an OntologyAnnotation object\n",
    "nte1 = NonTreatment(element_type='screen', duration_unit=OntologyAnnotation(term=\"days\"))\n",
    "print(nte1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creation of another `ISA Study Design Element`, of type `Treatment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=radiological intervention, \n",
      "        factor_values=[])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "te1 = Treatment()\n",
    "te1.type='radiological intervention'\n",
    "print(te1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 defining the first treatment as a vector of ISA factor values:\n",
    "\n",
    "Under \"ISA Study Design Create mode\", a `Study Design Element` of type `Treatment` needs to be defined by a vector of `Factors` and their respective associated `Factor Values`. This is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactorValue(\n",
      "    factor_name=light\n",
      "    value='visible light at 3000K produced by LED array'\n",
      "    unit=\n",
      ") FactorValue(\n",
      "    factor_name=dose\n",
      "    value=250\n",
      "    unit=lux\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1 = StudyFactor(name='light', factor_type=OntologyAnnotation(term=\"electromagnetic energy\"))\n",
    "f1v = FactorValue(factor_name=f1, value=\"visible light at 3000K produced by LED array\")\n",
    "f2 = StudyFactor(name='dose', factor_type=OntologyAnnotation(term=\"quantity\"))\n",
    "\n",
    "# IMPORTANT: note how *FactorValue value* is supplied as an *numeral*\n",
    "f2v = FactorValue(factor_name=f2, value=250, unit=OntologyAnnotation(term='lux'))\n",
    "f3 = StudyFactor(name='duration', factor_type=OntologyAnnotation(term=\"time\"))\n",
    "f3v = FactorValue(factor_name=f3, value=1, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "print(f1v,f2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=radiological intervention, \n",
      "        factor_values=[isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='dose', factor_type=isatools.model.OntologyAnnotation(term='quantity', term_source=None, term_accession='', comments=[]), comments=[]), value=250, unit=isatools.model.OntologyAnnotation(term='lux', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='duration', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=1, unit=isatools.model.OntologyAnnotation(term='hr', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='light', factor_type=isatools.model.OntologyAnnotation(term='electromagnetic energy', term_source=None, term_accession='', comments=[]), comments=[]), value='visible light at 3000K produced by LED array', unit=None)])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "#assigning the factor values declared above to the ISA treatment element\n",
    "te1.factor_values = [f1v,f2v,f3v]\n",
    "print(te1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creation of a second  `ISA Study Design Element`, of type `Treatment`, following the same pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=radiological intervention, \n",
      "        factor_values=[isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='dose', factor_type=isatools.model.OntologyAnnotation(term='quantity', term_source=None, term_accession='', comments=[]), comments=[]), value=250, unit=isatools.model.OntologyAnnotation(term='lux', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='duration', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=1, unit=isatools.model.OntologyAnnotation(term='hour', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='light', factor_type=isatools.model.OntologyAnnotation(term='electromagnetic energy', term_source=None, term_accession='', comments=[]), comments=[]), value='visible light at 3000K produced by LED array', unit=None)])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "te3 = Treatment()\n",
    "te3.type = 'radiological intervention'\n",
    "rays = StudyFactor(name='light', factor_type=OntologyAnnotation(term=\"electromagnetic energy\"))\n",
    "\n",
    "raysv = FactorValue(factor_name=rays, value='visible light at 3000K produced by LED array')\n",
    "rays_intensity = StudyFactor(name='dose', factor_type=OntologyAnnotation(term=\"quantity\"))\n",
    "rays_intensityv= FactorValue(factor_name=rays_intensity, value = 250, unit=OntologyAnnotation(term='lux'))\n",
    "rays_duration =  StudyFactor(name = 'duration', factor_type=OntologyAnnotation(term=\"time\"))\n",
    "rays_durationv = FactorValue(factor_name=rays_duration, value=1, unit=OntologyAnnotation(term='hour'))\n",
    "\n",
    "te3.factor_values = [raysv,rays_intensityv,rays_durationv]\n",
    "print(te3)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creation of 'wash out' period as an `ISA Study Design Element`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonTreatment(\n",
      "            type='washout',\n",
      "            duration=isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='DURATION', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=0.0, unit=isatools.model.OntologyAnnotation(term='days', term_source=None, term_accession='', comments=[]))\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "# Creation of another ISA element, which is not a Treatment element, which is of type `screen` by default\n",
    "# nte2 = NonTreatment()\n",
    "# nte2.type = 'washout'\n",
    "# net2.duration_unit=OntologyAnnotation(term=\"days\")\n",
    "\n",
    "nte2 = NonTreatment(element_type='washout', duration_unit=OntologyAnnotation(term=\"days\"))\n",
    "print(nte2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setting the factor values associated with 'default' DURATION Factor associated with such elements\n",
    "nte2.duration.value=2\n",
    "nte2.duration.unit=OntologyAnnotation(term=\"weeks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creation of 'follow-up' period as an `ISA Study Design Element`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nte3 = NonTreatment(element_type='follow-up', duration_value=1, duration_unit=OntologyAnnotation(term=\"month\"))\n",
    "#print(nte3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Creation of the associated container, known as an ISA `Cell` for each ISA `Element`.\n",
    "In this example, a single `Element` is hosted by a `Cell`, which must be named. In more complex designs (e.g. study designs with assymetric arms), a `Cell` may contain more than one `Element`, hence the list attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_cl1= StudyCell(name=\"st_cl1\", elements=[nte1])\n",
    "st_cl2= StudyCell(name=\"st_cl2\", elements=[te1])\n",
    "st_cl3= StudyCell(name=\"st_cl3\", elements=[nte2])\n",
    "st_cl4= StudyCell(name=\"st_cl4\", elements=[te3])\n",
    "st_cl5= StudyCell(name=\"st_cl5\", elements=[nte3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Creation of an ISA `Study Arm` and setting the number of subjects associated to that unique sequence of ISA `Cell`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"StudyArm(\n",
      "               name=Arm 1,\n",
      "               source_type=Characteristic(\n",
      "    category=genotype\n",
      "    value=control - normal\n",
      "    unit=\n",
      "    comments=0 Comment objects\n",
      "),\n",
      "               group_size=2, \n",
      "               no. cells=0,\n",
      "               no. sample_assay_plans=0\n",
      "               )\n"
     ]
    }
   ],
   "source": [
    "genotype_cat = OntologyAnnotation(term=\"genotype\")\n",
    "genotype_value1 = OntologyAnnotation(term=\"control - normal\")\n",
    "genotype_value2 = OntologyAnnotation(term=\"mutant\")\n",
    "\n",
    "arm1 = StudyArm(\n",
    "    name='Arm 1', \n",
    "    group_size=2\n",
    ")\n",
    "\n",
    "arm1.source_type=Characteristic(\n",
    "    category=genotype_cat,\n",
    "    value=genotype_value1\n",
    ")\n",
    "\n",
    "print(arm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Declaring an ISA `Sample Assay Plan`, defining which `Sample` are to be collected and which `Assay`s to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whole_patient=ProductNode(\n",
    "    id_=\"MAT1\",\n",
    "    name=\"subject\",\n",
    "    node_type=SAMPLE,\n",
    "    size=1,\n",
    "    characteristics=[\n",
    "        Characteristic(\n",
    "            category=OntologyAnnotation(term='organism part'), \n",
    "            value=OntologyAnnotation(term='whole organism')\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "saliva=ProductNode(\n",
    "    id_=\"MAT2\",\n",
    "    name=\"saliva\",\n",
    "    node_type=SAMPLE,\n",
    "    size=1,\n",
    "    characteristics=[\n",
    "        Characteristic(\n",
    "            category=OntologyAnnotation(term='organism part'),\n",
    "            value=OntologyAnnotation(term='saliva')\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load an isa assay definition in the form of an ordered dictionary. It corresponds to an ISA configuration assay table but expressed in JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now show how to create an new AssayGraph structure from scratch, as if we were defining a completely new assay type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "light_sensitivity_phenotyping_1 = OrderedDict([\n",
    "    ('measurement_type', OntologyAnnotation(term='melatonine concentration')),\n",
    "    ('technology_type', OntologyAnnotation(term='radioimmunoprecipitation assay')),\n",
    "     ('extraction', {}),\n",
    "            ('extract', [\n",
    "                {\n",
    "                    'node_type': EXTRACT,\n",
    "                    'characteristics_category': OntologyAnnotation(term='extract type'),\n",
    "                    'characteristics_value': OntologyAnnotation(term='extract'),\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': None,\n",
    "                    'is_input_to_next_protocols': True\n",
    "                }]),\n",
    "                \n",
    "    ('radioimmunoprecipitation', {\n",
    "                OntologyAnnotation(term='instrument'): [OntologyAnnotation(term='Beckon Dickison XYZ')],\n",
    "                OntologyAnnotation(term='antibody'): [OntologyAnnotation(term='AbCam antiMelatonine ')],\n",
    "                OntologyAnnotation(term='time point'): [OntologyAnnotation(term='1 hr'),\n",
    "                                                        OntologyAnnotation(term='2 hr')]\n",
    "            }),\n",
    "            ('raw_data_file', [\n",
    "                {\n",
    "                    'node_type': DATA_FILE,\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': 1,\n",
    "                    'is_input_to_next_protocols': False\n",
    "                }\n",
    "            ])\n",
    "])\n",
    "\n",
    "\n",
    "light_sensitivity_phenotyping_2 = OrderedDict([\n",
    "        ('measurement_type', OntologyAnnotation(term='light sensitivity')),\n",
    "        ('technology_type', OntologyAnnotation(term='electroencephalography')),\n",
    "            ('data_collection', {\n",
    "                OntologyAnnotation(term='instrument'): [OntologyAnnotation(term='Somnotouch')],\n",
    "                OntologyAnnotation(term='sampling_rate'): [OntologyAnnotation(term='200 Hz')],\n",
    "                OntologyAnnotation(term='time point'): [OntologyAnnotation(term='1 hr'),\n",
    "                                                        OntologyAnnotation(term='2 hr')]\n",
    "            }),\n",
    "            ('raw_data_file', [\n",
    "                {\n",
    "                    'node_type': DATA_FILE,\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': 1,\n",
    "                    'is_input_to_next_protocols': False\n",
    "                }\n",
    "            ])\n",
    "])\n",
    "\n",
    "light_sensitivity_phenotyping_3 = OrderedDict([\n",
    "        ('measurement_type', OntologyAnnotation(term='light sensitivity phenotyping')),\n",
    "        ('technology_type', OntologyAnnotation(term='direct measurement')),\n",
    "            ('data_collection', {\n",
    "                OntologyAnnotation(term='variables'): [OntologyAnnotation(term='sleepiness'),\n",
    "                                                       OntologyAnnotation(term='heart rate'),\n",
    "                                                       OntologyAnnotation(term='pupilla size')],\n",
    "                OntologyAnnotation(term='time point'): [OntologyAnnotation(term='1 hr'),\n",
    "                                                        OntologyAnnotation(term='2 hr')]\n",
    "            }),\n",
    "            ('raw_data_file', [\n",
    "                {\n",
    "                    'node_type': DATA_FILE,\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': 1,\n",
    "                    'is_input_to_next_protocols': False\n",
    "                }\n",
    "            ])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alterness_assay_graph = AssayGraph.generate_assay_plan_from_dict(light_sensitivity_phenotyping_1)\n",
    "melatonine_assay_graph = AssayGraph.generate_assay_plan_from_dict(light_sensitivity_phenotyping_2)\n",
    "general_phenotyping_assay_graph = AssayGraph.generate_assay_plan_from_dict(light_sensitivity_phenotyping_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sap1 = SampleAndAssayPlan(name='sap1', sample_plan=[whole_patient,saliva],assay_plan=[alterness_assay_graph,melatonine_assay_graph,general_phenotyping_assay_graph])\n",
    "\n",
    "sap1.add_element_to_map(sample_node=saliva, assay_graph=melatonine_assay_graph)\n",
    "sap1.add_element_to_map(sample_node=whole_patient, assay_graph=alterness_assay_graph)\n",
    "sap1.add_element_to_map(sample_node=whole_patient,assay_graph=general_phenotyping_assay_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Declaration of an ISA assay and linking specimen type and data acquisition plan for this assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{isatools.create.model.ProductNode(id=MAT2, type=sample, name=saliva, characteristics=[isatools.model.Characteristic(category=isatools.model.OntologyAnnotation(term='organism part', term_source=None, term_accession='', comments=[]), value=isatools.model.OntologyAnnotation(term='saliva', term_source=None, term_accession='', comments=[]), unit=None, comments=[])], size=1, extension=None): {isatools.create.model.AssayGraph(id=cce3713d-dfd3-4942-8d87-cb391156d756, measurement_type=OntologyAnnotation(\n",
       "      term=light sensitivity\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), technology_type=OntologyAnnotation(\n",
       "      term=electroencephalography\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), nodes={isatools.create.model.ProductNode(id=raw_data_file_000_001, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProtocolNode(id=data_collection_001, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='Somnotouch', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='sampling_rate', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='200 Hz', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='2 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProtocolNode(id=data_collection_000, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='Somnotouch', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='sampling_rate', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='200 Hz', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='1 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_000, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None)}, links=[('data_collection_000', 'raw_data_file_000_000'), ('data_collection_001', 'raw_data_file_000_001')], quality_control=None)},\n",
       " isatools.create.model.ProductNode(id=MAT1, type=sample, name=subject, characteristics=[isatools.model.Characteristic(category=isatools.model.OntologyAnnotation(term='organism part', term_source=None, term_accession='', comments=[]), value=isatools.model.OntologyAnnotation(term='whole organism', term_source=None, term_accession='', comments=[]), unit=None, comments=[])], size=1, extension=None): {isatools.create.model.AssayGraph(id=05599bfb-d02b-471e-b9b1-6ce6758791db, measurement_type=OntologyAnnotation(\n",
       "      term=melatonine concentration\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), technology_type=OntologyAnnotation(\n",
       "      term=radioimmunoprecipitation assay\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), nodes={isatools.create.model.ProductNode(id=extract_000_000, type=extract, name=extract, characteristics=[isatools.model.Characteristic(category=isatools.model.OntologyAnnotation(term='extract type', term_source=None, term_accession='', comments=[]), value=isatools.model.OntologyAnnotation(term='extract', term_source=None, term_accession='', comments=[]), unit=None, comments=[])], size=1, extension=None), isatools.create.model.ProtocolNode(id=extraction_000, name=assay0 - extraction, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - extraction\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[]), isatools.create.model.ProtocolNode(id=radioimmunoprecipitation_001_000, name=assay0 - radioimmunoprecipitation, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - radioimmunoprecipitation\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='Beckon Dickison XYZ', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='antibody', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='AbCam antiMelatonine ', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='2 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_001, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProtocolNode(id=radioimmunoprecipitation_000_000, name=assay0 - radioimmunoprecipitation, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - radioimmunoprecipitation\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='Beckon Dickison XYZ', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='antibody', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='AbCam antiMelatonine ', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='1 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_000, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None)}, links=[('extract_000_000', 'radioimmunoprecipitation_000_000'), ('extract_000_000', 'radioimmunoprecipitation_001_000'), ('extraction_000', 'extract_000_000'), ('radioimmunoprecipitation_000_000', 'raw_data_file_000_000'), ('radioimmunoprecipitation_001_000', 'raw_data_file_000_001')], quality_control=None),\n",
       "  isatools.create.model.AssayGraph(id=d7726069-1823-4f49-b10c-8856036ad082, measurement_type=OntologyAnnotation(\n",
       "      term=light sensitivity phenotyping\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), technology_type=OntologyAnnotation(\n",
       "      term=direct measurement\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), nodes={isatools.create.model.ProductNode(id=raw_data_file_000_002, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProductNode(id=raw_data_file_000_003, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProtocolNode(id=data_collection_004, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='variables', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='pupilla size', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='1 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_004, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProtocolNode(id=data_collection_000, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='variables', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='sleepiness', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='1 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_001, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProtocolNode(id=data_collection_002, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='variables', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='heart rate', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='1 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProtocolNode(id=data_collection_005, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='variables', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='pupilla size', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='2 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProtocolNode(id=data_collection_003, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='variables', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='heart rate', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='2 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_005, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None), isatools.create.model.ProtocolNode(id=data_collection_001, name=assay0 - data_collection, protocol_type=OntologyAnnotation(\n",
       "      term=assay0 - data_collection\n",
       "      term_source=\n",
       "      term_accession=\n",
       "      comments=0 Comment objects\n",
       "  ), uri=, description=, version=, parameter_values=[isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='variables', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='sleepiness', term_source=None, term_accession='', comments=[]), unit=None, comments=[]), isatools.model.ParameterValue(category=isatools.model.ProtocolParameter(parameter_name=isatools.model.OntologyAnnotation(term='time point', term_source=None, term_accession='', comments=[]), comments=[]), value=isatools.model.OntologyAnnotation(term='2 hr', term_source=None, term_accession='', comments=[]), unit=None, comments=[])]), isatools.create.model.ProductNode(id=raw_data_file_000_000, type=data file, name=raw_data_file, characteristics=[], size=1, extension=None)}, links=[('data_collection_000', 'raw_data_file_000_000'), ('data_collection_001', 'raw_data_file_000_001'), ('data_collection_002', 'raw_data_file_000_002'), ('data_collection_003', 'raw_data_file_000_003'), ('data_collection_004', 'raw_data_file_000_004'), ('data_collection_005', 'raw_data_file_000_005')], quality_control=None)}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sap1.sample_to_assay_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Build an ISA `Study Design Arm` by adding the first set of ISA `Cells` and setting the `Sample Assay Plan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arm1.add_item_to_arm_map(st_cl1, sap1)\n",
    "# print(arm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Now expanding the `Arm` by adding a new `Cell`, which uses the same `Sample Assay Plan` as the one used in Cell #1.\n",
    "Of course, the `Sample Assay Plan` for this new `Cell` could be different. It would have to be to built as shown before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arm1.add_item_to_arm_map(st_cl2, sap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adding the last section of the Arm, with a cell which also uses the same sample assay plan.\n",
    "arm1.add_item_to_arm_map(st_cl3, sap1)\n",
    "arm1.add_item_to_arm_map(st_cl4, sap1)\n",
    "arm1.add_item_to_arm_map(st_cl5, sap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creation of additional ISA Study Arms and setting the number of subjects associated to that unique sequence of ISA Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arm2 = StudyArm(name='Arm 2')\n",
    "arm2.group_size=2\n",
    "arm2.source_type=Characteristic(category=genotype_cat,\n",
    "                                value=genotype_value2)\n",
    "\n",
    "# st_cl6= StudyCell(name=\"st_cl6\", elements=[nte1])\n",
    "# st_cl7= StudyCell(name=\"st_cl7\", elements=[te1])\n",
    "# st_cl8= StudyCell(name=\"st_cl8\", elements=[nte2])\n",
    "# st_cl9= StudyCell(name=\"st_cl9\", elements=[te3])\n",
    "# st_cl10= StudyCell(name=\"st_cl10\", elements=[nte3])\n",
    "\n",
    "\n",
    "\n",
    "arm2.source_type.category\n",
    "arm2.add_item_to_arm_map(st_cl1,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl4,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl2,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl5,sap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arm3 = StudyArm(name='Arm 3')\n",
    "arm3.group_size=2\n",
    "arm3.source_type=Characteristic(category=genotype_cat,\n",
    "                                value=genotype_value1\n",
    "                               )\n",
    "arm3.add_item_to_arm_map(st_cl1,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl2,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl4,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl5,sap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arm4 = StudyArm(name='Arm 4')\n",
    "arm4.group_size=2\n",
    "arm4.source_type=Characteristic(category=genotype_cat,\n",
    "                                value=genotype_value2)\n",
    "\n",
    "arm4.add_item_to_arm_map(st_cl1,sap1)\n",
    "arm4.add_item_to_arm_map(st_cl4,None)\n",
    "arm4.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm4.add_item_to_arm_map(st_cl2,None)\n",
    "arm4.add_item_to_arm_map(st_cl5,sap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. We can now create the ISA `Study Design` object, which will receive the `Arms` defined by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study_design_final= StudyDesign(name='trial design #1')\n",
    "# print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adding a study arm to the study design object.\n",
    "study_design_final.add_study_arm(arm1)\n",
    "study_design_final.add_study_arm(arm2)\n",
    "study_design_final.add_study_arm(arm3)\n",
    "study_design_final.add_study_arm(arm4)\n",
    "\n",
    "study_finale = study_design_final.generate_isa_study()\n",
    "investigation1.studies.append(study_finale)\n",
    "# print(investigation1.studies[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's now serialize the ISA study design to JSON\n",
    "from isatools.create.model import StudyDesignEncoder\n",
    "\n",
    "f=json.dumps(study_design_final, cls=StudyDesignEncoder, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "\n",
    "final_dir = os.path.abspath(os.path.join('notebook-output', 'isa-study-custom-assay-light-sensitivity'))\n",
    "\n",
    "with open(os.path.join(final_dir,'./light-sensitivity-study_design_final.json'), 'w') as isa_sdf_jf:\n",
    "    json.dump(json.loads(f), isa_sdf_jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 17:43:54,822 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [3, 4, 5, 6]\n",
      "2021-07-21 17:43:54,828 [WARNING]: isatab.py(write_study_table_files:1194) >> [8, 7, 3, 10, 9, 12, 11, 14, 13, 16, 15, 18, 17, 20, 19, 22, 21, 24, 23, 26, 25, 28, 27, 30, 29, 32, 31, 34, 33, 36, 35, 38, 37, 40, 39, 42, 41, 44, 43, 46, 45, 48, 47, 4, 50, 49, 52, 51, 54, 53, 56, 55, 58, 57, 60, 59, 62, 61, 64, 63, 66, 65, 68, 67, 70, 69, 72, 71, 74, 73, 76, 75, 78, 77, 80, 79, 82, 81, 84, 83, 86, 85, 88, 87, 5, 90, 89, 92, 91, 94, 93, 96, 95, 98, 97, 100, 99, 102, 101, 104, 103, 106, 105, 108, 107, 110, 109, 112, 111, 114, 113, 116, 115, 118, 117, 120, 119, 122, 121, 124, 123, 126, 125, 128, 127, 6, 130, 129, 132, 131, 134, 133, 136, 135, 138, 137, 140, 139, 142, 141, 144, 143, 146, 145, 148, 147, 150, 149]\n",
      "2021-07-21 17:43:54,829 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[3, 8, 7], [3, 10, 9], [3, 12, 11], [3, 14, 13], [3, 16, 15], [3, 18, 17], [3, 20, 19], [3, 22, 21], [3, 24, 23], [3, 26, 25], [3, 28, 27], [3, 30, 29], [3, 32, 31], [3, 34, 33], [3, 36, 35], [3, 38, 37], [3, 40, 39], [3, 42, 41], [3, 44, 43], [3, 46, 45], [4, 48, 47], [4, 50, 49], [4, 52, 51], [4, 54, 53], [4, 56, 55], [4, 58, 57], [4, 60, 59], [4, 62, 61], [4, 64, 63], [4, 66, 65], [4, 68, 67], [4, 70, 69], [4, 72, 71], [4, 74, 73], [4, 76, 75], [4, 78, 77], [4, 80, 79], [4, 82, 81], [4, 84, 83], [4, 86, 85], [5, 88, 87], [5, 90, 89], [5, 92, 91], [5, 94, 93], [5, 96, 95], [5, 98, 97], [5, 100, 99], [5, 102, 101], [5, 104, 103], [5, 106, 105], [5, 108, 107], [5, 110, 109], [5, 112, 111], [5, 114, 113], [5, 116, 115], [5, 118, 117], [5, 120, 119], [5, 122, 121], [5, 124, 123], [5, 126, 125], [6, 130, 129], [6, 132, 131], [6, 134, 133], [6, 136, 135], [6, 138, 137], [6, 140, 139], [6, 142, 141], [6, 144, 143], [6, 146, 145], [6, 148, 147], [6, 150, 149], [6, 128, 127]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sample Name.0.Factor Value[DURATION]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5n/rl6lqnks4rqb59pbtpvvntqw0000gr/T/ipykernel_17990/2479725034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0misatools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misatab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0misatab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0misatools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misatab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_tables_to_dataframes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdumpdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/lib/python3.9/site-packages/isatools/isatab.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(isa_obj, output_path, i_file_name, skip_dump_tables, write_factor_values_in_assay_table)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mwrite_study_table_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         write_assay_table_files(\n\u001b[1;32m   1051\u001b[0m             investigation, output_path, write_factor_values_in_assay_table)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/lib/python3.9/site-packages/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_study_table_files\u001b[0;34m(inv_obj, output_dir)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         fvlabel = \"{0}.Factor Value[{1}]\".format(\n\u001b[1;32m   1296\u001b[0m                             olabel, fv.factor_name.name)\n\u001b[0;32m-> 1297\u001b[0;31m                         \u001b[0mwrite_value_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m         \"\"\"if isinstance(pbar, ProgressBar):\n\u001b[1;32m   1299\u001b[0m             pbar.finish()\"\"\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/lib/python3.9/site-packages/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_value_columns\u001b[0;34m(df_dict, label, x)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOntologyAnnotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".Unit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".Unit.Term Source REF\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sample Name.0.Factor Value[DURATION]'"
     ]
    }
   ],
   "source": [
    "# print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "from isatools import isatab\n",
    "isatab.dump(investigation1, final_dir)\n",
    "\n",
    "from isatools.isatab import dump_tables_to_dataframes as dumpdf\n",
    "dataframes = dumpdf(investigation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "- authors: philippe.rocca-serra@oerc.ox.ac.uk, massimiliano.izzo@oerc.ox.ac.uk\n",
    "- license: CC-BY 4.0\n",
    "- support: isatools@googlegroups.com\n",
    "- issue tracker: https://github.com/ISA-tools/isa-api/issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa-api-py39",
   "language": "python",
   "name": "isa-api-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
